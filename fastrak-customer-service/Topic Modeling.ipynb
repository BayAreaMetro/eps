{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all data\n",
    "xls = pd.ExcelFile('./Compiled_survey.xlsx')\n",
    "Jan18 = pd.read_excel(xls, 'Jan 2018')\n",
    "Jan18['month'] = 'Jan 2018'\n",
    "Dec17 = pd.read_excel(xls, 'Dec 2017')\n",
    "Dec17['month'] = 'Dec 2017'\n",
    "Nov17 = pd.read_excel(xls, 'Nov 2017')\n",
    "Nov17['month'] = 'Nov 2017'\n",
    "Oct17 = pd.read_excel(xls, 'Oct 2017')\n",
    "Oct17['month'] = 'Oct 2017'\n",
    "Sept17 = pd.read_excel(xls, 'Sept 2017')\n",
    "Sept17['month'] = 'Sept 2017'\n",
    "Aug17 = pd.read_excel(xls, 'August 2017')\n",
    "Aug17['month'] = 'Aug 2017'\n",
    "Jul17 = pd.read_excel(xls, 'July 2017')\n",
    "Jul17['month'] = 'Jul 2017'\n",
    "Jun17 = pd.read_excel(xls, 'June 2017')\n",
    "Jun17['month'] = 'Jun 2017'\n",
    "May17 = pd.read_excel(xls, 'May 2017')\n",
    "May17['month'] = 'May 2017'\n",
    "Apr17 = pd.read_excel(xls, 'April 2017')\n",
    "Apr17['month'] = 'April 2017'\n",
    "Mar17 = pd.read_excel(xls, 'Mar 2017')\n",
    "Mar17['month'] = 'March 2017'\n",
    "Feb17 = pd.read_excel(xls, 'Feb 2017')\n",
    "Feb17['month'] = 'Feb 2017'\n",
    "Jan17 = pd.read_excel(xls, 'Jan 2017')\n",
    "Jan17['month'] = 'Jan 2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine data frames into one\n",
    "data = pd.concat([Jan18, Dec17, Nov17, Oct17, Sept17, Aug17, Jul17,Jun17, May17, Apr17,\n",
    "         Mar17, Feb17, Jan17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "data = data.rename(index=str, columns={\"Date\":\"date\", \"What is the purpose for your visit today?\": \"purpose\",\n",
    "                                 'Were you able to complete your task today?':\"task_completion\",\n",
    "                                 \"How would you rate the level of effort you had to put forth to handle your request today?\": \"effort\",\n",
    "                                 'How did this effort compare to your expectations?':'expectations',\n",
    "                                 'How likely is it that you would recommend FasTrak to a friend or colleague?':'recommend',\n",
    "                                 \"Additional Feedback (Optional)\": \"feedback\",\n",
    "                                \"month\":\"month\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneeded column \n",
    "data = data.drop('#', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jul 2017      15012\n",
       "Aug 2017      14988\n",
       "Jan 2017      14375\n",
       "Jun 2017      14068\n",
       "April 2017    14068\n",
       "Feb 2017      14068\n",
       "May 2017      14068\n",
       "March 2017    14068\n",
       "Oct 2017      14061\n",
       "Jan 2018      13809\n",
       "Sept 2017     13237\n",
       "Nov 2017      13237\n",
       "Dec 2017      11579\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"month\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180638, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for only rows with feedback responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get only rows with feedback filled out\n",
    "feedback = data[data.feedback.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jul 2017      3056\n",
       "Aug 2017      2919\n",
       "Oct 2017      2721\n",
       "Jan 2018      2668\n",
       "Jun 2017      2664\n",
       "Jan 2017      2627\n",
       "March 2017    2588\n",
       "Nov 2017      2551\n",
       "Sept 2017     2551\n",
       "April 2017    2379\n",
       "Dec 2017      2202\n",
       "Feb 2017      2128\n",
       "May 2017      1561\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback[\"month\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32615, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter feedback for only responses with an issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out super positive feedback\n",
    "neg_feedback = feedback[\n",
    "        (feedback['expectations'] != 'Exceptional') &\n",
    "        (feedback['purpose'] == 'Dispute Violation/Invoice')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oct 2017      134\n",
       "Jan 2018      132\n",
       "Aug 2017      129\n",
       "Jul 2017      119\n",
       "Jan 2017      119\n",
       "Sept 2017     118\n",
       "Nov 2017      118\n",
       "Dec 2017      112\n",
       "Jun 2017      111\n",
       "March 2017    110\n",
       "April 2017    108\n",
       "Feb 2017       96\n",
       "May 2017       61\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_feedback[\"month\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_feedback.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1467"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile documents into a list\n",
    "doc_set = neg_feedback.feedback.tolist()\n",
    "\n",
    "#remove numbers from documents\n",
    "doc_set = [x for x in doc_set if type(x) != int]\n",
    "len(doc_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words only appearing once in whole list\n",
    "# https://stackoverflow.com/questions/21100903/improve-performance-remove-all-strings-in-a-big-list-appearing-only-once\n",
    "c = Counter(word for x in doc_set for word in x.split())\n",
    "doc_set = [' '.join(y for y in x.split() if c[y] > 1) for x in doc_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_modeling(doc_set = doc_set):\n",
    "    #create tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    # create English stop words list\n",
    "    en_stop = get_stop_words('en')\n",
    "\n",
    "    # Create p_stemmer of class PorterStemmer\n",
    "    p_stemmer = PorterStemmer()\n",
    "    \n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "\n",
    "    # loop through document list\n",
    "    for i in doc_set:\n",
    "        \n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "\n",
    "        # stem tokens\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        \n",
    "        # add tokens to list\n",
    "        texts.append(stemmed_tokens) # texts is a list of list of tokens for each doc (feedback response)\n",
    "    \n",
    "    # turn our tokenized documents into a id <-> term dictionary\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    \n",
    "    # convert tokenized documents into a document-term matrix\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    # generate LDA model\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=6, id2word = dictionary, \n",
    "                                           passes=20, minimum_probability=0)\n",
    "    return ldamodel, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel, corpus = topic_modeling(doc_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, u'0.027*\"fastrak\" + 0.026*\"charg\" + 0.023*\"account\" + 0.015*\"toll\"')\n",
      "(1, u'0.028*\"toll\" + 0.027*\"lane\" + 0.024*\"t\" + 0.020*\"use\"')\n",
      "(2, u'0.050*\"account\" + 0.042*\"vehicl\" + 0.035*\"violat\" + 0.027*\"notic\"')\n",
      "(3, u'0.029*\"violat\" + 0.023*\"plate\" + 0.020*\"m\" + 0.018*\"licens\"')\n",
      "(4, u'0.034*\"account\" + 0.015*\"violat\" + 0.015*\"time\" + 0.014*\"get\"')\n",
      "(5, u'0.030*\"t\" + 0.019*\"bridg\" + 0.019*\"time\" + 0.015*\"call\"')\n"
     ]
    }
   ],
   "source": [
    "for top in ldamodel.print_topics(num_topics=6, num_words=4):\n",
    "    print(top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretting results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/20984841/topic-distribution-how-do-we-see-which-document-belong-to-which-topic-after-doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns the topics to the documents in corpus\n",
    "lda_corpus = ldamodel[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16666666685\n"
     ]
    }
   ],
   "source": [
    "# Find the threshold, let's set the threshold to be 1/#clusters,\n",
    "# To prove that the threshold is sane, we average the sum of all probabilities:\n",
    "scores = list(chain(*[[score for topic_id,score in topic] \\\n",
    "                      for topic in [doc for doc in lda_corpus]]))\n",
    "threshold = sum(scores)/len(scores)\n",
    "print threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1 = [j for i,j in zip(lda_corpus,doc_set) if i[0][1] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster2 = [j for i,j in zip(lda_corpus,doc_set) if i[1][1] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster3 = [j for i,j in zip(lda_corpus,doc_set) if i[2][1] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster4 = [j for i,j in zip(lda_corpus,doc_set) if i[3][1] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster5 = [j for i,j in zip(lda_corpus,doc_set) if i[4][1] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster6 = [j for i,j in zip(lda_corpus,doc_set) if i[5][1] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print cluster1\n",
    "#print cluster2\n",
    "#print cluster3\n",
    "#print cluster4\n",
    "#print cluster5\n",
    "#print cluster6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
